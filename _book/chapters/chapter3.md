# 加载模型和分词器
model_path = "cmz1024/minimind-zero"  # 替换为你的模型路径
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)
```



至此，你就创建了一个展示demo, 把你的喜悦和进步分享给你的朋友吧。

![image-20250327201730558](https://for-note.oss-cn-shanghai.aliyuncs.com/img/image-20250327201730558.png)







### 快速开始的进阶思考 





### 小结

## 二、数据集



### 如何对文本进行编码？Tokenizer 



数据处理的第一步，就是使用数字对文本进行编码。 

Tokenizer，分词器，将文本划分成一个个最小单元 —词元(token),  用于模型训练。

以BERT、GPT等预训练语言模型为例，tokenizer的作用流程如下：

1. 输入文本："I love AI."
2. 分词器处理后：["I", "love", "AI", "."]
3. 再转成ID：[101, 2001, 727, 102]（假设的ID）
4. 输入到模型中。

词表(Vocabulary)是分词器的重要组件，将token转化成token_id。在训练前的语料处理，模型输出的解码阶段，都会用到词表。 词表重要参数就是词表大小，词表越大，能生成的语言越多。

常见的分词器有BPE、wordPiece等。 BPE在大模型广泛使用，而wordPiece则是在Bert中使用。两者都属于

子词分词器。



**什么是子词？**

子词是介于词和字符之间单元。 假如使用词作为单位来划分文本的话，颗粒度太大，词表无法兼容所有的词汇。 容易出现陌生词，也就是OOV问题(out-of-vocabulary) 。 假如使用字符来进行分词，颗粒度太小，token没有实际的含义。

子词兼有两者的优点。

比如： 常见英文单词的前缀和后缀，re，ful，ly。



**BPE(byte pair encoding)算法的原理 .**

它是如何训练，构建词表的呢？

先将要训练的文本集合，按照字符来进行拆分。拆分之后，将相邻字符组合，构成子词，统计子词的频率。

假设文本为，“Ｉ　love you”, 那么统计 I , Io,ov, yo, ou 的频率。

将频率高的子词，确定进行合并。 

再进行下一轮统计。将子词和相邻的字符或者子词合并，合并频率最高的。

直到达到词表的大小。



**wordPiece分词的原理。**

wordPiece是子词分词算法，在Bert等语言模型之中广泛使用。wordPiece和BPE的区别在与在进行子词合并的时候，考虑了语料的概率。也就是说，在分词之后，要确常见子词的概率。而BPE中仅根据出现频率来进行考虑。出现频率高的，不一定是常见子词。

假设我们有如下简单语料：

```
复制unhappiness
unhappy
unhappily
unhappiest
```

**1. BPE 的处理方式**

BPE 会统计所有连续字符对的出现频率，比如：

- “un”、“ha”、“pp”、“in”、“es”、“ly”、“est”等等

假设“pp”在语料中出现频率很高（比如在“happiness”、“happy”、“happily”、“happiest”里都出现了），BPE 可能会优先把“pp”合并成一个子词。

但有时候，某些字符对虽然频率高，却并不是有实际意义的子词（比如“pp”本身在英文中没有独立意义）。

**2. WordPiece 的处理方式**

WordPiece 不仅考虑“pp”的出现频率，还会计算如果把“pp”合并成一个子词，是否能显著提升整个语料的概率（即更好地表示原始语料中的单词）。

假设“un”、“happy”、“ness”、“ly”、“est”这些子词在英语中很常见，WordPiece 可能会更倾向于合并这些有实际意义的子词，而不是仅仅频率高但没意义的“pp”。

比如，WordPiece 可能会优先得到如下子词：

- “un”
- “happy”
- “ness”
- “ly”
- “est”

这样，“unhappiness”会被分成“un + happy + ness”，而不是“un + ha + pp + in + ess”。

### 

| 单词        | BPE 分词结果            | WordPiece 分词结果 |
| ----------- | ----------------------- | ------------------ |
| unhappiness | un + ha + pp + in + ess | un + happy + ness  |
| unhappily   | un + ha + pp + ily      | un + happy + ly    |
| unhappy     | un + ha + pp + y        | un + happy         |



### embedding — 把数字变成向量

经过分词之后，我们得到文本对应的token_id，也就是一串数字。



为什么需要把token_id转化成向量？

token_id 只是一个整数编号，本身没有任何语义信息。神经网络擅长处理**向量**（一组有意义的数字），而不是单一的整数。也就是说，只有转化成向量，才能进行语义表示，才能进行训练。



如何转化？

代码xx 



### 位置编码

位置编码是一种将



### 构建训练- 目标对





### 如何批量加载和组织数据？



### 常见的数据集格式：



### 数据集的进阶思考 

**元**

**反**

**空**

### 小结

## 三、自注意力机制 



### 为何Transfomer架构能够胜出？



先看看transformer之前的RNN和CNN. 



RNN和LSTM是什么 ? 

1. RNN（循环神经网络，Recurrent Neural Network）

**基本原理**

- RNN是一类用于处理序列数据的神经网络。
- 不同于传统的前馈神经网络，RNN在每个时间步都会接收当前输入和上一个时间步的“隐藏状态”作为输入，实现信息的“记忆”与传递。

**优点**

- 能处理变长的序列数据（如文本、语音、时间序列等）。
- 结构简单，参数共享，适合序列建模。

**缺点**

- **梯度消失/爆炸**：长序列训练时，梯度会迅速变小或变大，导致模型难以捕捉长距离依赖关系。
- 训练效率较低，不能并行。

LSTM（长短期记忆网络，Long Short-Term Memory）

**基本原理**

- LSTM是RNN的改进版，专门为了解决RNN的“长距离依赖”问题（即梯度消失/爆炸）。
- 通过引入“门控机制”，控制信息的“记忆”与“遗忘”。LSTM单元包含三个门：输入门、遗忘门、输出门。

| 特点       | RNN               | LSTM                     |
| ---------- | ----------------- | ------------------------ |
| 结构       | 简单              | 复杂（有门控）           |
| 长距离依赖 | 容易丢失          | 能较好捕捉               |
| 参数量     | 少                | 多                       |
| 训练难度   | 梯度消失/爆炸严重 | 缓解梯度消失/爆炸        |
| 计算速度   | 慢（不能并行）    | 慢（不能并行）           |
| 应用       | 简单序列建模      | 复杂序列建模，长依赖场景 |



transformer的优势在哪里？  

1. 并行计算能力强
RNN/LSTM：序列数据必须按时间步依次处理，不能并行（即第t步的输出依赖于第t-1步的输出），导致训练和推理速度慢。
Transformer：基于自注意力机制，所有位置的输入可以同时处理，实现完全并行，大幅提升训练效率。
2. 捕捉长距离依赖能力强
RNN/LSTM：虽然LSTM通过门控机制缓解了梯度消失问题，但长距离依赖仍然难以捕捉，信息传递路径长，容易丢失上下文信息。
Transformer：自注意力机制可以直接建立任意两个位置之间的联系，无论距离多远，捕捉长距离依赖效果更好。
3. 建模灵活
RNN/LSTM：只能顺序建模，难以处理非顺序结构的数据。
Transformer：通过自注意力机制，可以灵活地建模序列中任意位置之间的关系，更适合复杂结构的数据。
4. 扩展性强
RNN/LSTM：堆叠层数受限，层数多了易出现梯度消失或爆炸。
Transformer：结构简单，易于堆叠更深的网络层，提升模型容量和表达能力。
5. 更适合大规模数据和预训练
Transformer结构非常适合大规模数据的分布式训练，也是BERT、GPT等预训练模型的基础结构。
总结
RNN/LSTM：顺序处理、依赖前后关系、捕捉长距离依赖弱、不易并行。
Transformer：全局自注意力、并行处理、捕捉长距离依赖强、易扩展和预训练。



### 自注意力机制

自注意力机制是什么？  



自注意力机制是一种对**同一序列**内不同token之间的关系编码的技术，也就是能够将token和token之间的关系进行编码。

通过自注意力机制，序列中的token都会得到一个上下文向量（context -vector), 用于表示序列中上下文的信息。



**简单的自注意力机制**不包含**权重矩阵**，仅用于演示注意力机制的简单流程。权重矩阵是模型中可训练的参数。 



简单的自注意力机制的**实现流程**：

遍历序列中的token所对应的向量值。

计算当前向量和其它向量的点积，得到权重分数，权重分数经过 `softmax`函数归一化得到权重值。

序列中的所有向量 * 权重数进行累加，就得到当前token对应的上下文向量。



举例：

序列为：”我爱阅读“

对应的向量：(vector1, vetor2,vector3,vector4 )

当前的token为”我“，那么会用 vector1 *  vectori （i = 1,2,3,4）得到权重分数(score1,score2,score3,score4)

权重分数归一化之后得到(w1,w2,w3,w4)

最终得到，”我“对应的 context_vector1 =   w1 *vecotr1 + w2 * vector2 + w3 * vector3 + w4* vector4。 



在第二章根据token创建embeding的时候，仅考虑了单个toekn以及token在序列中的位置，没有考虑token之间的关系。

自注意力机制弥补了这个缺点，经过自注意力机制得到的上下文向量，能更好的表示token的，让模型获得更好地输出。





#### 权重分数

```
import torch

inputs = torch.tensor(
  [[0.43, 0.15, 0.89], # Your     (x^1)
   [0.55, 0.87, 0.66], # journey  (x^2)
   [0.57, 0.85, 0.64], # starts   (x^3)
   [0.22, 0.58, 0.33], # with     (x^4)
   [0.77, 0.25, 0.10], # one      (x^5)
   [0.05, 0.80, 0.55]] # step     (x^6)
)
```



```
