
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>注意力机制的进阶思考 · HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 6.0.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/@honkit/honkit-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="38-xiao-jie.html" />
    
    
    <link rel="prev" href="36-duo-tou-zhu-yi-li.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="01-ling-ji-chu-ru-men-da-mo-xing.html">
            
                <a href="01-ling-ji-chu-ru-men-da-mo-xing.html">
            
                    
                    零基础入门大模型
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="02-qian-yan.html">
            
                <a href="02-qian-yan.html">
            
                    
                    前言
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" data-path="03-ru-he-shi-yong-ben-shu.html">
            
                <a href="03-ru-he-shi-yong-ben-shu.html">
            
                    
                    如何使用本书
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="04-qwen2-5jie-shao.html">
            
                <a href="04-qwen2-5jie-shao.html">
            
                    
                    qwen2.5介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3" data-path="05-llama-factoryjie-shao.html">
            
                <a href="05-llama-factoryjie-shao.html">
            
                    
                    LLama-Factory介绍
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="06-yi-kuai-su-kai-shi-xun-lian-ni-de-di-yi-ge-mo-xing.html">
            
                <a href="06-yi-kuai-su-kai-shi-xun-lian-ni-de-di-yi-ge-mo-xing.html">
            
                    
                    一、快速开始 —  训练你的第一个模型
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="07-huan-jing-zhun-bei.html">
            
                <a href="07-huan-jing-zhun-bei.html">
            
                    
                    💻 环境准备
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="08-mo-xing-xun-lian.html">
            
                <a href="08-mo-xing-xun-lian.html">
            
                    
                    🚀 模型训练
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.2.1" data-path="09-yu-xun-lian-pretrain-rang-mo-xing-xue-xi-hai-liang-zhi-shi.html">
            
                <a href="09-yu-xun-lian-pretrain-rang-mo-xing-xue-xi-hai-liang-zhi-shi.html">
            
                    
                    预训练(pretrain) —— 让模型学习海量知识
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2.2" data-path="10-jian-du-wei-diao-sft-rang-mo-xing-xue-hui-shuo-hua.html">
            
                <a href="10-jian-du-wei-diao-sft-rang-mo-xing-xue-hui-shuo-hua.html">
            
                    
                    监督微调(sft) — 让模型学会说话
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" data-path="11-mo-xing-bu-shu.html">
            
                <a href="11-mo-xing-bu-shu.html">
            
                    
                    🌐 模型部署
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.3.1" data-path="12-zhuan-hua-wei-hfge-shi.html">
            
                <a href="12-zhuan-hua-wei-hfge-shi.html">
            
                    
                    转化为HF格式
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3.2" data-path="13-shang-chuan-dao-huggingface.html">
            
                <a href="13-shang-chuan-dao-huggingface.html">
            
                    
                    上传到 Huggingface
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3.3" data-path="14-chuang-jian-space-showchu-ni-de-mo-xing.html">
            
                <a href="14-chuang-jian-space-showchu-ni-de-mo-xing.html">
            
                    
                    创建Space，show出你的模型
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2.4" data-path="15-kuai-su-kai-shi-de-jin-jie-si-kao.html">
            
                <a href="15-kuai-su-kai-shi-de-jin-jie-si-kao.html">
            
                    
                    快速开始的进阶思考
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.5" data-path="16-xiao-jie.html">
            
                <a href="16-xiao-jie.html">
            
                    
                    小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="17-er-shu-ju-ji.html">
            
                <a href="17-er-shu-ju-ji.html">
            
                    
                    二、数据集
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.1" data-path="18-ru-he-dui-wen-ben-jin-xing-bian-ma-tokenizer.html">
            
                <a href="18-ru-he-dui-wen-ben-jin-xing-bian-ma-tokenizer.html">
            
                    
                    如何对文本进行编码？Tokenizer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.2" data-path="19-embedding-ba-shu-zi-bian-cheng-xiang-liang.html">
            
                <a href="19-embedding-ba-shu-zi-bian-cheng-xiang-liang.html">
            
                    
                    embedding — 把数字变成向量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.3" data-path="20-wei-zhi-bian-ma.html">
            
                <a href="20-wei-zhi-bian-ma.html">
            
                    
                    位置编码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4" data-path="21-gou-jian-xun-lian-mu-biao-dui.html">
            
                <a href="21-gou-jian-xun-lian-mu-biao-dui.html">
            
                    
                    构建训练- 目标对
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.5" data-path="22-ru-he-pi-liang-jia-zai-he-zu-zhi-shu-ju.html">
            
                <a href="22-ru-he-pi-liang-jia-zai-he-zu-zhi-shu-ju.html">
            
                    
                    如何批量加载和组织数据？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.6" data-path="23-chang-jian-de-shu-ju-ji-ge-shi.html">
            
                <a href="23-chang-jian-de-shu-ju-ji-ge-shi.html">
            
                    
                    常见的数据集格式：
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.7" data-path="24-shu-ju-ji-de-jin-jie-si-kao.html">
            
                <a href="24-shu-ju-ji-de-jin-jie-si-kao.html">
            
                    
                    数据集的进阶思考
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.8" data-path="25-xiao-jie.html">
            
                <a href="25-xiao-jie.html">
            
                    
                    小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="26-san-zi-zhu-yi-li-ji-zhi.html">
            
                <a href="26-san-zi-zhu-yi-li-ji-zhi.html">
            
                    
                    三、自注意力机制
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.1" data-path="27-wei-he-transfomerjia-gou-neng-gou-sheng-chu.html">
            
                <a href="27-wei-he-transfomerjia-gou-neng-gou-sheng-chu.html">
            
                    
                    为何Transfomer架构能够胜出？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.2" data-path="28-zi-zhu-yi-li-ji-zhi.html">
            
                <a href="28-zi-zhu-yi-li-ji-zhi.html">
            
                    
                    自注意力机制
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.2.1" data-path="29-quan-zhong-fen-shu.html">
            
                <a href="29-quan-zhong-fen-shu.html">
            
                    
                    权重分数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.2.2" data-path="30-quan-zhong.html">
            
                <a href="30-quan-zhong.html">
            
                    
                    权重
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.2.3" data-path="31-shang-xia-wen-xiang-liang.html">
            
                <a href="31-shang-xia-wen-xiang-liang.html">
            
                    
                    上下文向量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.2.4" data-path="32-qkvju-zhen.html">
            
                <a href="32-qkvju-zhen.html">
            
                    
                    QKV矩阵
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.4.3" data-path="33-yin-guo-zhu-yi-li.html">
            
                <a href="33-yin-guo-zhu-yi-li.html">
            
                    
                    因果注意力
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.3.1" data-path="34-yin-guo-zhu-yi-li-yan-ma.html">
            
                <a href="34-yin-guo-zhu-yi-li-yan-ma.html">
            
                    
                    因果注意力掩码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.3.2" data-path="35-dropoutji-zhi.html">
            
                <a href="35-dropoutji-zhi.html">
            
                    
                    dropout机制
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.4.4" data-path="36-duo-tou-zhu-yi-li.html">
            
                <a href="36-duo-tou-zhu-yi-li.html">
            
                    
                    多头注意力
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.4.5" data-path="37-zhu-yi-li-ji-zhi-de-jin-jie-si-kao.html">
            
                <a href="37-zhu-yi-li-ji-zhi-de-jin-jie-si-kao.html">
            
                    
                    注意力机制的进阶思考
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4.6" data-path="38-xiao-jie.html">
            
                <a href="38-xiao-jie.html">
            
                    
                    小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="39-si-shi-xian-yi-ge-gptmo-xing.html">
            
                <a href="39-si-shi-xian-yi-ge-gptmo-xing.html">
            
                    
                    四、实现一个GPT模型
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.5.1" data-path="40-zui-he-xin-mo-kuai-transformer-block.html">
            
                <a href="40-zui-he-xin-mo-kuai-transformer-block.html">
            
                    
                    最核心模块— transformer block
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.5.1.1" data-path="41-duo-tou-zhu-yi-li-ji-zhi.html">
            
                <a href="41-duo-tou-zhu-yi-li-ji-zhi.html">
            
                    
                    多头注意力机制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5.1.2" data-path="42-qian-kui-shen-jing-wang-luo.html">
            
                <a href="42-qian-kui-shen-jing-wang-luo.html">
            
                    
                    前馈神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5.1.3" data-path="43-ceng-gui-yi-hua.html">
            
                <a href="43-ceng-gui-yi-hua.html">
            
                    
                    层归一化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5.1.4" data-path="44-can-chai-lian-jie.html">
            
                <a href="44-can-chai-lian-jie.html">
            
                    
                    残差连接
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5.1.5" data-path="45-tranformer-blockdai-ma-shi-xian.html">
            
                <a href="45-tranformer-blockdai-ma-shi-xian.html">
            
                    
                    tranformer block代码实现
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.5.2" data-path="46-gptlei-shi-xian-shu-ju-shu-ru-shu-chu.html">
            
                <a href="46-gptlei-shi-xian-shu-ju-shu-ru-shu-chu.html">
            
                    
                    GPT类实现（数据输入，输出）
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.5.2.1" data-path="47-gpthe-xin-you-na-xie-zu-jian.html">
            
                <a href="47-gpthe-xin-you-na-xie-zu-jian.html">
            
                    
                    GPT核心有哪些组件？
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.5.3" data-path="48-jian-dan-wen-ben-sheng-cheng.html">
            
                <a href="48-jian-dan-wen-ben-sheng-cheng.html">
            
                    
                    简单文本生成
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5.4" data-path="49-gptjia-gou-de-jin-jie-si-kao.html">
            
                <a href="49-gptjia-gou-de-jin-jie-si-kao.html">
            
                    
                    GPT架构的进阶思考
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5.5" data-path="50-xiao-jie.html">
            
                <a href="50-xiao-jie.html">
            
                    
                    小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="51-wu-ru-he-xun-lian-mo-xing.html">
            
                <a href="51-wu-ru-he-xun-lian-mo-xing.html">
            
                    
                    五、如何训练模型
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.6.1" data-path="52-ru-he-ping-gu-mo-xing-de-shu-chu.html">
            
                <a href="52-ru-he-ping-gu-mo-xing-de-shu-chu.html">
            
                    
                    如何评估模型的输出？
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.6.1.1" data-path="53-jiao-cha-shang.html">
            
                <a href="53-jiao-cha-shang.html">
            
                    
                    交叉熵
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.1.2" data-path="54-kun-huo-du.html">
            
                <a href="54-kun-huo-du.html">
            
                    
                    困惑度
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.1.3" data-path="55-ji-suan-xun-lian-ji-he-yan-zheng-ji-de-sun-shi.html">
            
                <a href="55-ji-suan-xun-lian-ji-he-yan-zheng-ji-de-sun-shi.html">
            
                    
                    计算训练集和验证集的损失
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.6.2" data-path="56-mo-xing-xun-lian-de-ji-ben-liu-cheng.html">
            
                <a href="56-mo-xing-xun-lian-de-ji-ben-liu-cheng.html">
            
                    
                    模型训练的基本流程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.3" data-path="57-gao-jie-de-xun-lian-ji-qiao.html">
            
                <a href="57-gao-jie-de-xun-lian-ji-qiao.html">
            
                    
                    高阶的训练技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.4" data-path="58-jie-ma-ce-lue.html">
            
                <a href="58-jie-ma-ce-lue.html">
            
                    
                    解码策略
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.5" data-path="59-mo-xing-xun-lian-de-de-jin-jie-si-kao.html">
            
                <a href="59-mo-xing-xun-lian-de-de-jin-jie-si-kao.html">
            
                    
                    模型训练的的进阶思考
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.6" data-path="60-xiao-jie.html">
            
                <a href="60-xiao-jie.html">
            
                    
                    小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="61-liu-ru-he-shi-yong-llamafactorywei-diao-mo-xing.html">
            
                <a href="61-liu-ru-he-shi-yong-llamafactorywei-diao-mo-xing.html">
            
                    
                    六、如何使用LLamaFactory微调模型
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.7.1" data-path="62-lorawei-diao.html">
            
                <a href="62-lorawei-diao.html">
            
                    
                    Lora微调
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.2" data-path="63-llamafactoryde-wei-diao-liu-cheng.html">
            
                <a href="63-llamafactoryde-wei-diao-liu-cheng.html">
            
                    
                    LLamaFactory的微调流程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.3" data-path="64-shu-ju-ji-gou-jian.html">
            
                <a href="64-shu-ju-ji-gou-jian.html">
            
                    
                    数据集构建
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.4" data-path="65-can-shu-she-zhi.html">
            
                <a href="65-can-shu-she-zhi.html">
            
                    
                    参数设置
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.5" data-path="66-kai-shi-xun-lian.html">
            
                <a href="66-kai-shi-xun-lian.html">
            
                    
                    开始训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.6" data-path="67-shu-ju-wei-diao-de-jin-jie-si-kao.html">
            
                <a href="67-shu-ju-wei-diao-de-jin-jie-si-kao.html">
            
                    
                    数据微调的进阶思考
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.7" data-path="68-xiao-jie.html">
            
                <a href="68-xiao-jie.html">
            
                    
                    小结
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="69-qi-fu-lu.html">
            
                <a href="69-qi-fu-lu.html">
            
                    
                    七、附录
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="70-zhang-liang-de-ji-ben-cao-zuo.html">
            
                <a href="70-zhang-liang-de-ji-ben-cao-zuo.html">
            
                    
                    张量的基本操作
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >注意力机制的进阶思考</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="注意力机制的进阶思考">注意力机制的进阶思考</h1>
<p><strong>元</strong></p>
<p>本质上是XXX</p>
<p><strong>反</strong></p>
<p>多头注意力机制的计算量过大。  </p>
<p><strong>空</strong></p>
<ul>
<li>MHA，ＭＱＡ，GQA对比:</li>
</ul>
<p>MHA ，多头注意力机制，transformer论文中提出。</p>
<p>ＭＱＡ， MHA 改进版，每个头有一个Q，所有的头共享KV矩阵。</p>
<p>GQA，　综合版，每个头有一个Q，有多组的KV。</p>
<table>
<thead>
<tr>
<th>机制</th>
<th>Query</th>
<th>Key/Value</th>
<th>参数量/速度</th>
<th>表达能力</th>
</tr>
</thead>
<tbody>
<tr>
<td>MHA</td>
<td>每头独立</td>
<td>每头独立</td>
<td>参数最多/慢</td>
<td>最强</td>
</tr>
<tr>
<td>MQA</td>
<td>每头独立</td>
<td>全部头共享</td>
<td>参数最少/最快</td>
<td>较弱</td>
</tr>
<tr>
<td>GQA</td>
<td>每头独立</td>
<td>每组头共享</td>
<td>参数适中/较快</td>
<td>适中</td>
</tr>
</tbody>
</table>
<ul>
<li>FlashAttention是什么？</li>
</ul>
<p>flashAttention是一种高效的注意力机制实现方式。 传统的注意力计算的方法, 需要计算QK(T)矩阵相乘，时间复杂度为O(n2), 再对大矩阵进行softmax.  flashAttention的核心为，将大矩阵分成block，以block作为核心计算矩阵乘法运算，以及归一化计算。有了flashAttention之后，可以提高计算的效率。</p>
<pre><code>┌──────────────┐
│   Q, K, V    │
└─────┬────────┘
      │
      ▼
┌──────────────┐
│ 分块加载小块 │
└─────┬────────┘
      │
      ▼
┌──────────────┐
│ 计算分数     │
│ 边softmax    │
│ 边加权求和   │
└─────┬────────┘
      │
      ▼
┌──────────────┐
│ 处理下一个块 │
└──────────────┘
</code></pre><ul>
<li>KVcache的原理</li>
</ul>
<p>大模型一次吐出一个词。在原始的transformer中，在推理的时候，需要计算重新计算历史token的KV，新的token要生成KVQ，用Q去查询历史token的KV，捕捉特征。 因此历史的KV完全可以复用 。</p>
<p>kv-cache 的 shape 是</p>
<p>[batch_size, n_heads, past_seq_len, head_dim]</p>
<p>past_seq_len：历史token长度，会随着生成步数增长。 </p>
<p>kv-cache面临内存增长的问题，目前有的办法是将模型分到不同的GPU上，或者采用量化的方式减少显存使用。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>维度（多头）</th>
<th>用途</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q</td>
<td>[batch, n_heads, seq_len, head_dim]</td>
<td>当前token查询向量</td>
</tr>
<tr>
<td>K</td>
<td>[batch, n_heads, seq_len, head_dim]</td>
<td>历史token键向量</td>
</tr>
<tr>
<td>V</td>
<td>[batch, n_heads, seq_len, head_dim]</td>
<td>历史token值向量</td>
</tr>
<tr>
<td>kv-cache K</td>
<td>[batch, n_heads, past_seq_len, head_dim]</td>
<td>缓存历史K</td>
</tr>
<tr>
<td>kv-cache V</td>
<td>[batch, n_heads, past_seq_len, head_dim]</td>
<td>缓存历史V</td>
</tr>
</tbody>
</table>
<ul>
<li>VLLM的加速原理</li>
</ul>
<p>pageAttention 和 Continuous Batching</p>
<p>传统的kv-cache在进行管理的时候，会分配一个大张量，张量的size为(layer, batch_size, sequence_length, heaer_count,  head_dim)</p>
<p>sequence_length 通常会padding到同一个长度，导致显存浪费。并且分配大张量，会导致显存碎片。</p>
<p>你猜到了吗？ pageAttention 和内存的分页管理思想一样, 不再给请求分配一个大块显存。而是给先将显存分割成较小的页，同一个请求可以横跨不同的页。多个请求的kv可以拼接在一个大张量里。这样不会造成padding浪费。</p>
<p>当请求过来，通过<strong>页表</strong>查询历史token在那一页。</p>
<p>pageAttention,  kv进行矩阵运算的时候，是不是要copy一份? 　并不是。</p>
<p> 在做Attention计算时，<strong>通过高效的索引（gather/scatter）操作，把需要的kv在计算时“逻辑上拼成”一个连续矩阵</strong></p>
<p><strong>Continuous Batching</strong>  , 能够将不同时间发起来的请求，拼接到一个batch里推理,GPU利用率更高，相应更快。</p>
<p>也就是能动态的扩展当前batch </p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="36-duo-tou-zhu-yi-li.html" class="navigation navigation-prev " aria-label="Previous page: 多头注意力">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="38-xiao-jie.html" class="navigation navigation-next " aria-label="Next page: 小结">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"注意力机制的进阶思考","level":"1.2.4.5","depth":3,"next":{"title":"小结","level":"1.2.4.6","depth":3,"path":"38-xiao-jie.md","ref":"38-xiao-jie.md","articles":[]},"previous":{"title":"多头注意力","level":"1.2.4.4","depth":3,"path":"36-duo-tou-zhu-yi-li.md","ref":"36-duo-tou-zhu-yi-li.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"37-zhu-yi-li-ji-zhi-de-jin-jie-si-kao.md","mtime":"2025-06-02T13:12:56.869Z","type":"markdown"},"gitbook":{"version":"6.0.3","time":"2025-06-02T13:13:17.722Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/@honkit/honkit-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

